A crucial problem in audio signal processing, environmental sound classification has applications in intelligent settings, smart cities, and surveillance systems. Environmental noises are difficult to recognize because, in contrast to speech, they are unstructured, non-stationary, and frequently tainted with background noise. Using the UrbanSound8K dataset, this work suggests a deep learning-based method for environmental sound classification. Convolutional Neural Network (CNN) architectures are used in parallel to extract Mel-Frequency Cepstral Coefficients (MFCCs) and Mel Spectrogram features from audio sources. To increase generalization, the model uses adaptive learning rate scheduling, batch normalization, dropout regularization, early stopping, and data augmentation. Accuracy, precision, recall, F1-score, and confusion matrix metrics were used to confirm the experimental results, which show strong categorization performance across ten urban sound categories.
